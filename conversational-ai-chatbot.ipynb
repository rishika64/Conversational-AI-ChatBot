{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Conversational AI ChatBot](https://www.kaggle.com/rajkumarl/conversational-ai-chatbot)\n\n### Intelligent ChatBot built with Microsoft's DialoGPT transformer to make conversations with human users! \n\n![cover image](https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/Images/robo%20girl.jpg)\n> ##### [Image by Andy Kelly](https://unsplash.com/@askkell) ","metadata":{}},{"cell_type":"markdown","source":"### What is a chatbot?\n\n>##### A ChatBot is a kind of virtual assistant that can build conversations with human users! A *Chat*ting Ro*bot*. Building a chatbot is one of the popular tasks in Natural Language Processing.\n\n### Are all chatbots the same?\n>##### Chatbots fall under three common categories:\n>##### 1. Rule-based chatbots\n>##### 2. Retrieval-based chatbots\n>##### 3. Intelligent chatbots\n\n### Rule-based chatbots\n>##### These bots respond to users' inputs based on certain pre-specified rules. For instance, these rules can be defined as if-elif-else statements. While writing rules for these chatbots, it is important to expect all possible user inputs, else the bot may fail to answer properly. Hence, rule-based chatbots do not possess any cognitive skills.\n\n### Retrieval-based chatbots\n>##### These bots respond to users' inputs by retrieving the most relevant information from the given text document. The most relevant information can be determined by Natural Language Processing with a scoring system such as cosine-similarity-score. Though these bots use NLP to do conversations, they lack cognitive skills to match a real human chatting companion.\n\n### Intelligent AI chatbots\n>##### These bots respond to users' inputs after understanding the inputs, as humans do. These bots are trained with a Machine Learning Model on a large training dataset of human conversations. These bots are cognitive to match a human in conversing. Amazon's Alexa, Apple's Siri fall under this category. Further, most of these bots can make conversations based on the preceding chat texts.\n\n### In this Article?\n>##### This article describes building an intelligent AI chatbot based on the famous transformer architecture - Microsoft's DialoGPT. According to [Hugging Face's model card](https://huggingface.co/microsoft/DialoGPT-medium), DialoGPT is a State-Of-The-Art large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread.\n","metadata":{}},{"cell_type":"markdown","source":"# Let's Python\n\n##### Import necessary libraries and frameworks","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport time\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-26T14:19:55.973861Z","iopub.execute_input":"2021-12-26T14:19:55.974761Z","iopub.status.idle":"2021-12-26T14:20:03.838978Z","shell.execute_reply.started":"2021-12-26T14:19:55.974630Z","shell.execute_reply":"2021-12-26T14:20:03.838024Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Download Microsoft's DialoGPT model and tokenizer\n\n##### The Hugging Face checkpoint for the model and its tokenizer is `\"microsoft/DialoGPT-medium\"`","metadata":{}},{"cell_type":"code","source":"# checkpoint \ncheckpoint = \"microsoft/DialoGPT-medium\"\n# download and cache tokenizer\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n# download and cache pre-trained model\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T14:20:03.840758Z","iopub.execute_input":"2021-12-26T14:20:03.840995Z","iopub.status.idle":"2021-12-26T14:20:39.541497Z","shell.execute_reply.started":"2021-12-26T14:20:03.840967Z","shell.execute_reply":"2021-12-26T14:20:39.540683Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b64c6946ec64ee3bf098484a8586b8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8638a49c1a648c5af76f88763564127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4512c097f31c4fec9c847a840c9a76e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ac8b0c97a5e46ecbb3ec320e6e02b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/823M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3fd3a20ac804b0bb1e01e7b1cd425a5"}},"metadata":{}}]},{"cell_type":"markdown","source":"# A ChatBot class","metadata":{}},{"cell_type":"code","source":"# Build a ChatBot class with all necessary modules to make a complete conversation\nclass ChatBot():\n    # initialize\n    def __init__(self):\n        # once chat starts, the history will be stored for chat continuity\n        self.chat_history_ids = None\n        # make input ids global to use them anywhere within the object\n        self.bot_input_ids = None\n        # a flag to check whether to end the conversation\n        self.end_chat = False\n        # greet while starting\n        self.welcome()\n        \n    def welcome(self):\n        print(\"Initializing ChatBot ...\")\n        # some time to get user ready\n        time.sleep(2)\n        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n        # give time to read what has been printed\n        time.sleep(3)\n        # Greet and introduce\n        greeting = np.random.choice([\n            \"Welcome, I am ChatBot, here for your kind service\",\n            \"Hey, Great day! I am your virtual assistant\",\n            \"Hello, it's my pleasure meeting you\",\n            \"Hi, I am a ChatBot. Let's chat!\"\n        ])\n        print(\"ChatBot >>  \" + greeting)\n        \n    def user_input(self):\n        # receive input from user\n        text = input(\"User    >> \")\n        # end conversation if user wishes so\n        if text.lower().strip() in ['bye', 'quit', 'exit']:\n            # turn flag on \n            self.end_chat=True\n            # a closing comment\n            print('ChatBot >>  See you soon! Bye!')\n            time.sleep(1)\n            print('\\nQuitting ChatBot ...')\n        else:\n            # continue chat, preprocess input text\n            # encode the new user input, add the eos_token and return a tensor in Pytorch\n            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, \\\n                                                       return_tensors='pt')\n\n    def bot_response(self):\n        # append the new user input tokens to the chat history\n        # if chat has already begun\n        if self.chat_history_ids is not None:\n            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n        else:\n            # if first entry, initialize bot_input_ids\n            self.bot_input_ids = self.new_user_input_ids\n        \n        # define the new chat_history_ids based on the preceding chats\n        # generated a response while limiting the total chat history to 1000 tokens, \n        self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, \\\n                                               pad_token_id=tokenizer.eos_token_id)\n            \n        # last ouput tokens from bot\n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n                               skip_special_tokens=True)\n        # in case, bot fails to answer\n        if response == \"\":\n            response = self.random_response()\n        # print bot response\n        print('ChatBot >>  '+ response)\n        \n    # in case there is no response from model\n    def random_response(self):\n        i = -1\n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        # iterate over history backwards to find the last token\n        while response == '':\n            i = i-1\n            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        # if it is a question, answer suitably\n        if response.strip() == '?':\n            reply = np.random.choice([\"I don't know\", \n                                     \"I am not sure\"])\n        # not a question? answer suitably\n        else:\n            reply = np.random.choice([\"Great\", \n                                      \"Fine. What's up?\", \n                                      \"Okay\"\n                                     ])\n        return reply","metadata":{"execution":{"iopub.status.busy":"2021-12-26T14:20:39.542956Z","iopub.execute_input":"2021-12-26T14:20:39.543226Z","iopub.status.idle":"2021-12-26T14:20:39.560797Z","shell.execute_reply.started":"2021-12-26T14:20:39.543196Z","shell.execute_reply":"2021-12-26T14:20:39.559941Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Happy Chatting!","metadata":{}},{"cell_type":"code","source":"# build a ChatBot object\nbot = ChatBot()\n# start chatting\nwhile True:\n    # receive user input\n    bot.user_input()\n    # check whether to end chat\n    if bot.end_chat:\n        break\n    # output bot response\n    bot.bot_response()    ","metadata":{"execution":{"iopub.status.busy":"2021-12-26T14:20:39.562463Z","iopub.execute_input":"2021-12-26T14:20:39.562675Z","iopub.status.idle":"2021-12-26T14:30:15.474514Z","shell.execute_reply.started":"2021-12-26T14:20:39.562650Z","shell.execute_reply":"2021-12-26T14:30:15.473438Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Initializing ChatBot ...\nType \"bye\" or \"quit\" or \"exit\" to end chat \n\nChatBot >>  Hey, Great day! I am your virtual assistant\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  hi, how are you?\n"},{"name":"stdout","text":"ChatBot >>  I'm good, how are you?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Great. Are you a computer programmer?\n"},{"name":"stdout","text":"ChatBot >>  I am not. I'm a software engineer.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  what languages do you know?\n"},{"name":"stdout","text":"ChatBot >>  I know Java, Python, and C.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  great. how many software projects have you done?\n"},{"name":"stdout","text":"ChatBot >>  I have a few.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  who created python?\n"},{"name":"stdout","text":"ChatBot >>  I created Python.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  that's awesome.\n"},{"name":"stdout","text":"ChatBot >>  I'm a python developer.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  great. do you have a github account?\n"},{"name":"stdout","text":"ChatBot >>  I have a github account.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  ok. are you good at web development?\n"},{"name":"stdout","text":"ChatBot >>  I'm good at web development.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  wow. have you developed any mobile app?\n"},{"name":"stdout","text":"ChatBot >>  Fine. What's up?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  It is my pleasure meeting you!\n"},{"name":"stdout","text":"ChatBot >>  Fine. What's up?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Bye\n"},{"name":"stdout","text":"ChatBot >>  See you soon! Bye!\n\nQuitting ChatBot ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Some sample chats by this ChatBot\n\n![chat1](https://raw.githubusercontent.com/RajkumarGalaxy/Conversational-AI-ChatBot/main/chatbot_chats_1.jpg)","metadata":{}},{"cell_type":"markdown","source":"##### Thank you for your valuable time!\nFind this notebook on Kaggle here: https://www.kaggle.com/rajkumarl/conversational-ai-chatbot","metadata":{}}]}